{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmkurumi/colab/blob/main/%E3%80%8Ctacotron2_vits%E5%8D%95%E4%BA%BA_%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%E9%9B%86_20230217_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2k2feEG7yqa"
      },
      "source": [
        "## 补充说明\n",
        "\n",
        "1. demucs和slicer2可以自由选择，demucs默认放在前面以求slicer2分得更细；<br />如果因音频过长出错，可先执行slicer2后执行demucs\n",
        "\n",
        "2. slicer2不是AI，是算法分割音频\n",
        "\n",
        "3. 清除缓存会重置对应步骤产生的影响，但会删除对应步骤产生的数据，谨慎操作\n",
        "\n",
        "4. 默认勾选`wv_show_log` 以便于排错，如果觉得输出的东西太影响视野可以勾掉，还你一个清爽的界面\n",
        "\n",
        "5. 如果执行过程中出现一时解决不了的错误想要保留中间产物，或者demucs分离人声后想要保留背景音，<br />可以在导出时在 `wv_export_way` 填2，将过程中产生的所有文件打包保存到云盘\n",
        "\n",
        "6. whisper转写有一定出错概率，能找到原台词一般还是原台词更好"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO6XCA2ebBNV"
      },
      "source": [
        "## 准备"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXnb0kKXBkRa",
        "outputId": "0652831c-c380-4915-e863-df9b24978b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@markdown 加载云端硬盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aujPs55mCAbZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da8f044c-6b29-44d6-ea61-67b2469d03f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-7build1).\n",
            "The following NEW packages will be installed:\n",
            "  p7zip-rar\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 44.8 kB of archives.\n",
            "After this operation, 118 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 p7zip-rar amd64 16.02-3build1 [44.8 kB]\n",
            "Fetched 44.8 kB in 1s (45.7 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package p7zip-rar.\n",
            "(Reading database ... 128208 files and directories currently installed.)\n",
            "Preparing to unpack .../p7zip-rar_16.02-3build1_amd64.deb ...\n",
            "Unpacking p7zip-rar (16.02-3build1) ...\n",
            "Setting up p7zip-rar (16.02-3build1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (0.12.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.25.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.14)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting demucs\n",
            "  Downloading demucs-4.0.0.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dora-search\n",
            "  Downloading dora_search-0.1.11.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting diffq>=0.2.1\n",
            "  Downloading diffq-0.2.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.3/446.3 KB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting julius>=0.2.3\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lameenc>=1.2\n",
            "  Downloading lameenc-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.6/189.6 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openunmix\n",
            "  Downloading openunmix-1.2.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from demucs) (6.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from demucs) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchaudio>=0.8 in /usr/local/lib/python3.8/dist-packages (from demucs) (0.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from demucs) (4.64.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from diffq>=0.2.1->demucs) (0.29.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from diffq>=0.2.1->demucs) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.1->demucs) (4.5.0)\n",
            "Collecting submitit\n",
            "  Downloading submitit-1.4.5-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retrying\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treetable\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from retrying->dora-search->demucs) (1.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from submitit->dora-search->demucs) (2.2.1)\n",
            "Building wheels for collected packages: demucs, julius, dora-search, antlr4-python3-runtime, treetable\n",
            "  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demucs: filename=demucs-4.0.0-py3-none-any.whl size=76524 sha256=8e25aecfea0d3e2a69a29e770d5915cccf948d1760349b08a9fb4bc2a9a97538\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/cb/a0/6f6e765f7ba4669316f1679645b7770655f0a9e4b1a572303c\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21895 sha256=a230356f4f3336d3310fd28091184215ab97cececac2421788196f2c775c793f\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/89/4f/88596b58a42ee452100fe1cd6ac31265bb192e597cf85908da\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dora-search: filename=dora_search-0.1.11-py3-none-any.whl size=75008 sha256=323fb38aa01a7e5c64721bc19fdfc899b137472188c991fe3350d3cd58237353\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/42/69/2259709315acf43bd7b9876fb35454db01f770b63519966ac9\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=2dba5cfbfe77f4f60613b10151f0c2851557ea801b5c643f20a65a79cb3949b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7347 sha256=2fa4efdc615c21fa44f36bcb5bd3a67c00fb7981e9e7fa710cd2c69366918915\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/ac/31/490968d6fc824620f9f04f03a2f90149bbbbcdb6c6e614909c\n",
            "Successfully built demucs julius dora-search antlr4-python3-runtime treetable\n",
            "Installing collected packages: lameenc, antlr4-python3-runtime, treetable, submitit, retrying, omegaconf, einops, julius, dora-search, diffq, openunmix, demucs\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 demucs-4.0.0 diffq-0.2.3 dora-search-0.1.11 einops-0.6.0 julius-0.2.7 lameenc-1.4.2 omegaconf-2.3.0 openunmix-1.2.1 retrying-1.3.4 submitit-1.4.5 treetable-0.2.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-y8w8lsz7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-y8w8lsz7\n",
            "  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.26.14)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179424 sha256=ea5afded8f29566c18080df641a86040461787750974e0ad25418a4cd2aa8d84\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-14p8t37u/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tokenizers, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.12.1 openai-whisper-20230124 tokenizers-0.13.2 transformers-4.26.1\n",
            "Cloning into './slicer'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 88 (delta 34), reused 25 (delta 25), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (88/88), 25.02 KiB | 914.00 KiB/s, done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "#@markdown 安装依赖\n",
        "\n",
        "wv_show_log = True #@param :{type: \"boolean\"}\n",
        "\n",
        "def do_install():\n",
        "  wv_log_option = \"\" if wv_show_log else \">/dev/null 2>&1\"\n",
        "  !sudo apt install ffmpeg {wv_log_option}\n",
        "  !sudo apt-get install p7zip-full p7zip-rar {wv_log_option}\n",
        "  !pip install librosa soundfile {wv_log_option}\n",
        "  !pip install demucs {wv_log_option}\n",
        "  !pip install git+https://github.com/openai/whisper.git {wv_log_option}\n",
        "  !git clone --recursive https://github.com/openvpi/audio-slicer ./slicer {wv_log_option}\n",
        "  !pip install pydub {wv_log_option}\n",
        " \n",
        "do_install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RtkRN_ZHRvGL"
      },
      "outputs": [],
      "source": [
        "#@markdown 定义常量和引入库\n",
        "import os\n",
        "import whisper\n",
        "import librosa  # Optional. Use any library you like to read audio files.\n",
        "import soundfile  # Optional. Use any library you like to write audio files.\n",
        "from tqdm import tqdm\n",
        "from slicer.slicer2 import Slicer\n",
        "\n",
        "WV_RAW_DIR = \"raws\"  \n",
        "WV_WAV_DIR = \"wavs\"\n",
        "WV_OLD_WAV_DIR = \"old_wavs\"\n",
        "WV_RAW_WAV_DIR = \"raw_wavs\"\n",
        "WV_TMP_DIR = \"tmp\"\n",
        "WV_FILELIST_DIR = \"filelists\" \n",
        "WV_FILELIST_FILE = \"list.txt\" \n",
        "WV_WHISPER_TMP_DIR = f\"{WV_WAV_DIR}_before\"\n",
        "\n",
        "wv_whisper_model = 0\n",
        "\n",
        "def wv_clean_empty_lines_for_one(filename):\n",
        "    file_in = open(filename, \"r\", encoding=\"utf-8\")\n",
        "    content = file_in.readlines()\n",
        "    file_in.close()\n",
        "    file_out = open(filename, \"w\", encoding=\"utf-8\")\n",
        "    for i in range(len(content)):\n",
        "        line = content[i]\n",
        "        line = line.strip()\n",
        "        if len(line) == 0:\n",
        "            continue\n",
        "        if i == len(content) - 1:\n",
        "            print(line, file=file_out, end=\"\")\n",
        "        else:\n",
        "            print(line, file=file_out)\n",
        "    file_out.close()\n",
        "\n",
        "def wv_clean_empty_lines_for_all():\n",
        "  for _, _, files in os.walk(WV_FILELIST_DIR):\n",
        "    for file in tqdm(files):\n",
        "      wv_result_file = f'{WV_FILELIST_DIR}/{file}'\n",
        "      wv_clean_empty_lines_for_one(wv_result_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_4pTh4hrgjxt"
      },
      "outputs": [],
      "source": [
        "#@markdown 清除上次解压缓存\n",
        "wv_check_if = False #@param {type: \"boolean\"}\n",
        "if wv_check_if:\n",
        "  !rm -rf {WV_RAW_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OCgeabZOA-HC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe40d62-9d34-454a-da04-0915d104b968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/MyDrive/dataset/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "ERROR: No such file or directory\n",
            "/content/drive/MyDrive/dataset/YOUR_AUDIO_FILES.7z\n",
            "\n",
            "\n",
            "\n",
            "System ERROR:\n",
            "Unknown error -2147024894\n"
          ]
        }
      ],
      "source": [
        "#@markdown 解压\n",
        "wv_show_log = True #@param :{type: \"boolean\"}\n",
        "def fun_unzip():\n",
        "  wv_log_option = \"\" if wv_show_log else \">/dev/null 2>&1\"\n",
        "  os.makedirs(WV_RAW_DIR, exist_ok=True)\n",
        "  wv_raw_path = \"/content/drive/MyDrive/dataset/YOUR_AUDIO_FILES.7z\" #@param {type: \"string\"}\n",
        "  !7z e {wv_raw_path} -o{WV_RAW_DIR} {wv_log_option}\n",
        "fun_unzip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9SHa9Xy3rZ8"
      },
      "source": [
        "## 处理流程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYEL8yrEg6eO"
      },
      "outputs": [],
      "source": [
        "#@markdown 清除上次demucs缓存\n",
        "wv_check_if = False #@param {type: \"boolean\"}\n",
        "if wv_check_if:\n",
        "  !rm -rf {WV_WAV_DIR} {WV_TMP_DIR} {WV_RAW_WAV_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XBdhxLOVYRCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "q0_jW7jbYRVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0pJb6NAxV1M3"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 使用 demucs 去除背景杂音？（用时较长）\n",
        "wv_use_demucs = True #@param {type: \"boolean\"}\n",
        "# #@markdown 在过程结束（成功或失败）时删除临时文件？\n",
        "# wv_use_demucs_delete_tmp = False #@param {type: \"boolean\"}\n",
        "#@markdown 显示转换过程日志\n",
        "wv_show_log = True #@param :{type: \"boolean\"}\n",
        "#@markdown 选择模型\n",
        "wv_demucs_model_name = \"htdemucs_6s\" #@param {type: \"string\"}\n",
        "\n",
        "# (raws -> wavs)\n",
        "\n",
        "# wavs  -> raw_wavs\n",
        "#       -> wavs\n",
        "def fun_use_demucs():\n",
        "  if not os.path.exists(WV_WAV_DIR):\n",
        "    !cp -r {WV_RAW_DIR} {WV_WAV_DIR}\n",
        "  !mv {WV_WAV_DIR} {WV_RAW_WAV_DIR}\n",
        "  !mkdir {WV_WAV_DIR}\n",
        "  wv_log_option = \"\" if wv_show_log else \">/dev/null 2>&1\"\n",
        "  for _, _, files in os.walk(WV_RAW_WAV_DIR):\n",
        "    files.sort()\n",
        "    for file in tqdm(files):\n",
        "      old_file = f'{WV_RAW_WAV_DIR}/{file}'\n",
        "      new_file = f'{WV_WAV_DIR}/{\".\".join(file.split(\".\")[:-1])}.wav'\n",
        "      filename = file.split('.')[0]\n",
        "      !demucs --two-stems=vocals {old_file} -o {WV_TMP_DIR} -n {wv_demucs_model_name} {wv_log_option}\n",
        "      !ffmpeg -i {WV_TMP_DIR}/{wv_demucs_model_name}/{filename}/vocals.wav  -acodec pcm_s16le -ac 1 -ar 22050 {new_file} {wv_log_option}\n",
        "  # if wv_use_demucs_delete_tmp:\n",
        "  #  !rm -rf {WV_TMP_DIR}\n",
        "\n",
        "if wv_use_demucs:\n",
        "  fun_use_demucs()\n",
        "\n",
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Pbm1eEHEUa"
      },
      "source": [
        "关于demucs模型选择 （摘自官方[readme](https://github.com/facebookresearch/demucs/blob/main/README.md)）\n",
        "\n",
        "The list of pre-trained models is:\n",
        "- `htdemucs`: first version of Hybrid Transformer Demucs. Trained on MusDB + 800 songs. Default model.\n",
        "- `htdemucs_ft`: fine-tuned version of `htdemucs`, separation will take 4 times more time\n",
        "    but might be a bit better. Same training set as `htdemucs`.\n",
        "- `htdemucs_6s`: 6 sources version of `htdemucs`, with `piano` and `guitar` being added as sources.\n",
        "    Note that the `piano` source is not working great at the moment.\n",
        "- `hdemucs_mmi`: Hybrid Demucs v3, retrained on MusDB + 800 songs.\n",
        "- `mdx`: trained only on MusDB HQ, winning model on track A at the [MDX][mdx] challenge.\n",
        "- `mdx_extra`: trained with extra training data (including MusDB test set), ranked 2nd on the track B\n",
        "    of the [MDX][mdx] challenge.\n",
        "- `mdx_q`, `mdx_extra_q`: quantized version of the previous models. Smaller download and storage\n",
        "    but quality can be slightly worse.\n",
        "- `SIG`: where `SIG` is a single model from the [model zoo](docs/training.md#model-zoo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HH1fNg39gyj-"
      },
      "outputs": [],
      "source": [
        "#@markdown 清除上次slicer2缓存\n",
        "wv_check_if = False #@param {type: \"boolean\"}\n",
        "if wv_check_if:\n",
        "  if os.path.exists(WV_OLD_WAV_DIR):\n",
        "    !rm -rf {WV_WAV_DIR}\n",
        "    !mv {WV_OLD_WAV_DIR} {WV_WAV_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5xpXueT0DBdg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 使用 [slicer2](https://github.com/openvpi/audio-slicer) 分割音频？\n",
        "\n",
        "wv_use_slicer = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown 下面的参数可以不改动\n",
        "wv_slicer_threshold   = -40   #@param {type: \"integer\"}\n",
        "wv_slicer_min_length  = 5000  #@param {type: \"integer\"}\n",
        "wv_slicer_min_interval= 300   #@param {type: \"integer\"}\n",
        "wv_slicer_hop_size    = 10    #@param {type: \"integer\"}\n",
        "wv_slicer_max_sil_kept= 100   #@param {type: \"integer\"}\n",
        "\n",
        "# wavs -> old_wavs\n",
        "#      -> wavs\n",
        "def fun_use_slicer():\n",
        "  if not os.path.exists(WV_WAV_DIR):\n",
        "    !cp -r {WV_RAW_DIR} {WV_WAV_DIR}\n",
        "  !mv {WV_WAV_DIR} {WV_OLD_WAV_DIR}\n",
        "  os.makedirs(WV_WAV_DIR, exist_ok=True)\n",
        "  for _, _, files in os.walk(WV_OLD_WAV_DIR):\n",
        "    files.sort()\n",
        "    for file in tqdm(files):\n",
        "      audio, sr = librosa.load(f'{WV_OLD_WAV_DIR}/{file}', sr=None, mono=False)  # Load an audio file with librosa.\n",
        "      slicer = Slicer(\n",
        "          sr=sr,\n",
        "          threshold=wv_slicer_threshold,\n",
        "          min_length=wv_slicer_min_length,\n",
        "          min_interval=wv_slicer_min_interval,\n",
        "          hop_size=wv_slicer_hop_size,\n",
        "          max_sil_kept=wv_slicer_max_sil_kept\n",
        "      )\n",
        "      chunks = slicer.slice(audio)\n",
        "      for i, chunk in enumerate(chunks):\n",
        "          if len(chunk.shape) > 1:\n",
        "              chunk = chunk.T  # Swap axes if the audio is stereo.\n",
        "          filename = file.split('.')[0]\n",
        "          soundfile.write(f'{WV_WAV_DIR}/{filename}_{str(i).zfill(4)}.wav', chunk, sr)  # Save sliced\n",
        "if wv_use_slicer:\n",
        "  fun_use_slicer()\n",
        "else:\n",
        "  !cp -r {WV_RAW_DIR} {WV_WAV_DIR}\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BUxuP9PxhEI7"
      },
      "outputs": [],
      "source": [
        "#@markdown 清除上次whisper缓存\n",
        "wv_check_if = False #@param {type: \"boolean\"}\n",
        "if wv_check_if:\n",
        "  wv_whisper_model = 0\n",
        "  if os.path.exists(WV_WHISPER_TMP_DIR):\n",
        "    !rm -rf {WV_WAV_DIR}\n",
        "    !mv {WV_WHISPER_TMP_DIR} {WV_WAV_DIR}\n",
        "  !rm -rf {WV_FILELIST_DIR} /content/whisper-vits-japanese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hoorYo08S694"
      },
      "outputs": [],
      "source": [
        "#@markdown ### whisper 转写 (用时较长)\n",
        "\n",
        "#@markdown **单个音频不能超过30秒，可使用前面的slicer2分割**\n",
        "\n",
        "#@markdown 0 - 不使用whisper转写\n",
        "\n",
        "#@markdown 1 - 直接使用whisper转写\n",
        "\n",
        "#@markdown 2 - 调用 [auto.py](https://github.com/AlexandaJerry/whisper-vits-japanese/blob/main/auto.py) 进一步分割音频\n",
        "wv_whisper_option = 1 #@param {type: \"integer\"}\n",
        "#@markdown whisper 语种\n",
        "wv_language = \"Japanese\" #@param {type: \"string\"}\n",
        "#@markdown whisper 模型\n",
        "wv_whisper_model_name = \"large\" #@param {type: \"string\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2jwAR4fLSWe"
      },
      "source": [
        "关于whisper模型选择 （摘自官方[readme](https://github.com/openai/whisper/blob/main/README.md)）\n",
        "\n",
        "**Available models and languages**\n",
        "\n",
        "There are five model sizes, four with English-only versions, offering speed and accuracy tradeoffs. Below are the names of the available models and their approximate memory requirements and relative speed. \n",
        "\n",
        "\n",
        "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wO-D3qS5De4h"
      },
      "outputs": [],
      "source": [
        "#@markdown 转写方式1 - 直接使用whisper转写\n",
        "\n",
        "# snippet in https://github.com/openai/whisper/blob/main/README.md\n",
        "\n",
        "# load model\n",
        "def fun_use_whisper_way1_01():\n",
        "  global wv_whisper_model\n",
        "  if wv_whisper_model == 0:\n",
        "    wv_whisper_model = whisper.load_model(wv_whisper_model_name)\n",
        "# use model\n",
        "def fun_use_whisper_way1_02():\n",
        "  os.makedirs(WV_FILELIST_DIR, exist_ok=True)\n",
        "  wv_result_file = f'{WV_FILELIST_DIR}/{WV_FILELIST_FILE}'\n",
        "  wv_result = open(wv_result_file, \"a\", encoding=\"utf-8\")\n",
        "\n",
        "  for _, _, files in os.walk(WV_WAV_DIR):\n",
        "    files.sort()\n",
        "    for file in tqdm(files):\n",
        "      audio = whisper.load_audio(f\"{WV_WAV_DIR}/{file}\")\n",
        "      audio = whisper.pad_or_trim(audio)\n",
        "      mel = whisper.log_mel_spectrogram(audio).to(wv_whisper_model.device)\n",
        "      options = whisper.DecodingOptions(language=wv_language)\n",
        "      result = whisper.decode(wv_whisper_model, mel, options)\n",
        "      print(f'wavs/{file}|{result.text}', file=wv_result)\n",
        "\n",
        "if wv_whisper_option == 1:\n",
        "  fun_use_whisper_way1_01()\n",
        "  fun_use_whisper_way1_02()\n",
        "  wv_clean_empty_lines_for_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "snc5RYR_TyNA"
      },
      "outputs": [],
      "source": [
        "#@markdown 转写方式2 - 调用 auto.py 进一步分割音频\n",
        "# import logging\n",
        "#@markdown Forked from: https://github.com/AlexandaJerry/whisper-vits-japanese/blob/main/Whisper_Vits_Japanese.ipynb\n",
        "def wv_split_way2_01():\n",
        "  # logging.setLevel(logging.INFO)\n",
        "\n",
        "  print(f'1. dependency')\n",
        "  wv_use_split_repo = \"https://github.com/wind4000/whisper-vits-japanese\" #@param {type: \"string\"}\n",
        "  wv_use_split_branch = \"fix-regex\" #@param {type: \"string\"}\n",
        "  !git clone {wv_use_split_repo} -b {wv_use_split_branch}\n",
        "\n",
        "  print(f'2. prepare')\n",
        "  wvj_audio_dir = f'whisper-vits-japanese/audio/'\n",
        "  # !cp /content/whisper-vits-japanese/whisper/transcribe.py /usr/local/lib/python3.8/dist-packages/whisper\n",
        "  # !cp /content/whisper-vits-japanese/whisper/utils.py /usr/local/lib/python3.8/dist-packages/whisper\n",
        "  !rm -rf {wvj_audio_dir}\n",
        "  !cp -r {WV_WAV_DIR} {wvj_audio_dir}\n",
        "\n",
        "  print(f'3. whisper transcribe')\n",
        "  for _, _, files in os.walk(wvj_audio_dir):\n",
        "    files.sort()\n",
        "    print(files)\n",
        "    files = \" \".join([wvj_audio_dir + file for file in files])\n",
        "    !whisper {files} -o /content/whisper-vits-japanese/srt_files --language {wv_language} --model {wv_whisper_model_name}\n",
        "\n",
        "def wv_split_way2_02():\n",
        "  print(f'4. run whisper-vits-japanese/auto.py')\n",
        "  %cd /content/whisper-vits-japanese\n",
        "  !python auto.py\n",
        "  %cd /content\n",
        "\n",
        "  print(f'5. final')\n",
        "  os.makedirs(WV_FILELIST_DIR, exist_ok=True)\n",
        "  !cp /content/whisper-vits-japanese/filelists/train_filelist.txt {WV_FILELIST_DIR}/{WV_FILELIST_FILE}\n",
        "  !sed -i \"s;/content/whisper-vits-japanese/sliced_audio/;wavs/;\" {WV_FILELIST_DIR}/{WV_FILELIST_FILE}\n",
        "  !mv {WV_WAV_DIR} {WV_WAV_DIR}_before\n",
        "  !mv /content/whisper-vits-japanese/sliced_audio {WV_WAV_DIR}\n",
        "\n",
        "  wv_clean_empty_lines_for_all()\n",
        "  \n",
        "  print(f'\\n6. done')\n",
        "\n",
        "if wv_whisper_option == 2:\n",
        "  %cd /content\n",
        "  wv_split_way2_01()\n",
        "  wv_split_way2_02()\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOdM9Rwa3hS0"
      },
      "source": [
        "## 导出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "I4g4GLbuFnUW"
      },
      "outputs": [],
      "source": [
        "#@markdown 导出方式\n",
        "\n",
        "#@markdown 0 - 不导出\n",
        "\n",
        "#@markdown 1 - 导出filelists和wavs\n",
        "\n",
        "#@markdown 2 - 导出全部文件\n",
        "wv_export_way = 1 #@param {type: \"integer\"}\n",
        "wv_done_path = \"/content/drive/MyDrive/dataset/YOUR_DATASET.7z\" #@param {type: \"string\"}\n",
        "\n",
        "def fun_export():\n",
        "  if os.path.isfile(wv_done_path):\n",
        "    print(\"指定的路径已存在文件，会修改或覆盖原文件，请更换文件名\")\n",
        "    return\n",
        "  if wv_export_way == 1:\n",
        "    !7z a {wv_done_path} {WV_FILELIST_DIR}/ {WV_WAV_DIR}/\n",
        "    return\n",
        "  if wv_export_way == 2:\n",
        "    !7z a {wv_done_path} /content -xr!drive -xr!sample_data\n",
        "    return\n",
        "fun_export()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}